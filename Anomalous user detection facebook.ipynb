{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de dados 1\n",
    "\n",
    "Esses dados consistem do número de 'Likes' para cada um dos 9000 usuários, ao longo de 6 meses, em cada uma das 210 categorias que o Facebook atribui a cada página\n",
    "\n",
    "Cada linha de spatial é um usuário e cada coluna é uma categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the spatial dataset as a numpy array\n",
    "\n",
    "data = np.loadtxt('data/social/data/spatial_data.txt')\n",
    "spatial = data[:,1:]\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# pd.DataFrame(spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de dados 2\n",
    "\n",
    "Esses dados contém o número de 'Likes' para cada um dos 9000 usuários, ao longo de 6 meses, agregados diariamente.\n",
    "\n",
    "Linhas de FBTemporal são usuários e colunas são dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.loadtxt('data/social/data/temporal_data.txt')\n",
    "# FBTemporal = data[:,1:]\n",
    "# pd.DataFrame(FBTemporal[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the data matrix to make the use of PCA possible (in each column, mean = 0 and standard deviation = 1)\n",
    "\n",
    "std_spatial = StandardScaler().fit_transform(spatial)\n",
    "# pd.DataFrame(std_spatial).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>4.152</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.479</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-1.022</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.477</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>0.856</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>3.931</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>-0.557</td>\n",
       "      <td>-0.794</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>-1.053</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.236</td>\n",
       "      <td>-0.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.257</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1      2      3      4      5      6      7      8      9    ...  \\\n",
       "0  0.024 0.015 -0.041 -0.075 -0.013 -0.259 -0.048 -0.221 -0.254 -0.016  ...   \n",
       "1 -0.005 0.032 -0.003 -0.005  0.009 -0.066 -0.027 -0.037  0.034 -0.017  ...   \n",
       "2 -0.479 0.362 -1.022  0.309  0.477 -1.062  0.856 -0.646  3.931 -0.012  ...   \n",
       "3 -0.006 0.031 -0.004 -0.005  0.001 -0.073 -0.027 -0.038  0.031 -0.017  ...   \n",
       "4 -0.007 0.023 -0.013  0.006  0.005 -0.066  0.257 -0.035  0.042 -0.016  ...   \n",
       "5  0.001 0.033  0.001  0.009  0.011 -0.068 -0.022 -0.039  0.031 -0.017  ...   \n",
       "6 -0.019 0.027 -0.043 -0.009 -0.017 -0.080 -0.065 -0.045  0.030 -0.016  ...   \n",
       "7 -0.010 0.025 -0.044  0.011  0.009  0.232 -0.068 -0.040  0.045 -0.016  ...   \n",
       "8 -0.009 0.026 -0.004 -0.014 -0.011  0.197 -0.026 -0.048  0.015 -0.016  ...   \n",
       "9  0.001 0.034 -0.000  0.010  0.008 -0.071 -0.023 -0.041  0.029 -0.017  ...   \n",
       "\n",
       "     200    201    202    203    204    205    206    207    208    209  \n",
       "0 -0.080 -0.045  0.016 -0.120  4.152 -0.031 -0.127 -0.052 -0.062 -0.119  \n",
       "1 -0.010 -0.008  0.022 -0.007 -0.002  0.002  0.008 -0.014 -0.015 -0.018  \n",
       "2 -0.367 -0.048 -0.761 -0.557 -0.794 -0.533 -1.053 -0.186  1.236 -0.212  \n",
       "3 -0.012 -0.008 -0.003 -0.003 -0.003  0.004  0.012 -0.011 -0.024 -0.022  \n",
       "4 -0.009 -0.007 -0.013 -0.010 -0.003 -0.003  0.005 -0.017 -0.019 -0.005  \n",
       "5 -0.011 -0.008 -0.001 -0.006 -0.003  0.004  0.011 -0.014 -0.014 -0.007  \n",
       "6 -0.015 -0.008 -0.049 -0.028 -0.021 -0.020 -0.026 -0.025 -0.037  0.161  \n",
       "7 -0.010 -0.009 -0.032 -0.040 -0.019 -0.027 -0.037 -0.036 -0.012  0.014  \n",
       "8 -0.016 -0.008  0.027 -0.001 -0.007  0.007  0.014 -0.008 -0.037  0.052  \n",
       "9 -0.011 -0.008 -0.002 -0.006 -0.004  0.003  0.010 -0.014 -0.017 -0.007  \n",
       "\n",
       "[10 rows x 210 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the PCA algorithm to give the normal subspace matrix which is 8982 x 5.\n",
    "# this allows the points of the user behavior matrix (X) to be projected into the normal subspace,\n",
    "# and it gives us the normal behavior portion. subtracting the normal behavior portion from X, we get\n",
    "# the residual portion of user behavior.\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(std_spatial)\n",
    "normal_subspace = pca.components_.T             # transposing because PCA in sklearn makes each eigenvector become a line instead of a column.\n",
    "normal_behavior_portion = (np.matmul(np.matmul(normal_subspace, normal_subspace.T), std_spatial.T)).T\n",
    "residual_behavior_portion = std_spatial - normal_behavior_portion\n",
    "\n",
    "# 210x5 5x210 210x8982 ?????\n",
    "\n",
    "# pd.DataFrame(normal_subspace)\n",
    "# pd.DataFrame(normal_behavior_portion).head(10)\n",
    "pd.DataFrame(residual_behavior_portion).head(10)\n",
    "# pd.DataFrame(normal_subspace).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  5.438\n",
       "1  0.430\n",
       "2 19.372\n",
       "3  0.508\n",
       "4  0.452\n",
       "5  0.270\n",
       "6  2.408\n",
       "7  1.480\n",
       "8  1.009\n",
       "9  0.299"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the l2 norm of each line in the residual behavior portion matrix.\n",
    "# the l2 norm is the squared root of the sum of squares of each element in a vector.\n",
    "# this value, along with a given threshold, is what makes possible to detect anomalous users.\n",
    "\n",
    "individual_norms = np.sqrt(np.sum(np.power(residual_behavior_portion, 2), axis = 1))\n",
    "\n",
    "pd.DataFrame(individual_norms).head(10)\n",
    "# individual_norms = sorted(individual_norms, reverse = False)\n",
    "# pd.DataFrame(sorted(individual_norms, reverse=False))\n",
    "# pd.DataFrame(np.argsort(-individual_norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the ECDF (empirical cumulative distribution function) of the norms matrix.\n",
    "# this gives us a graph with y corresponding to \n",
    "# the threshold will be selected as a value which will classify 3% of users as anomalous.\n",
    "# some of the code is from https://www.codementor.io/kripanshubharga/calculate-ecdf-in-python-gycltzxi3\n",
    "\n",
    "x_values = np.linspace(start=min(individual_norms), stop=max(individual_norms), num=len(individual_norms))\n",
    "data_size = individual_norms.size\n",
    "\n",
    "y_values = []\n",
    "for i in x_values:\n",
    "    temp = individual_norms[individual_norms <= i]\n",
    "    value = temp.size / data_size\n",
    "    y_values.append(value)\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('norms')\n",
    "plt.ylabel('fraction of norms')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cumulative_distribution = np.array(y_values)\n",
    "# ycut = np.array(np.where(cumulative_distribution >= 0.97)).T\n",
    "# pd.DataFrame(ycut)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
